<?xml version="1.0" encoding="UTF-8"?>
<SearchIndexes Version="1.0">
    <Documents>
        <Document ID="32">
            <Title>3.1 Netflix</Title>
            <Text>## 3.1 Netflix 

TBD  


## 3.1.1 Datenerhebung

Netflix weiß von jedem Nutzer, was er schaut, wann er schaut, wie lange er etwas schaut, an welcher Stelle aufgehört wurde, zu schauen und wie er auf den Film oder die Serie aufmerksam geworden ist.

Diese riesige Menge an Daten wird von Algorithmen beobachtet. Laut dem amerikanischen Magazin The Atlantic beschäftigt Netflix allein 800 Ingenieure, die sich nur mit diesem Algorithmus beschäftigen.

The Atlantic hat recherchiert, wie die Algorithmen funktionieren. Auf die Funktionsweise des Algorithmus gehe ich im nächsten Abschnitt *Speicherung / Algorithmus* näher ein.

Das Herzstück von Netflix ist sein Empfehlungsmechanismus. Dieser basiert auf dem Algorithmus, der CineMatch genannt wird. Um diesen Mechanismus noch weiter zu verbessern, wurde 2006 von Netflix-Chef Reed Hastings ein Wettbewerb “The Netflix Prize” zur Verbesserung des Algorithmus, ausgeschrieben. Er versprach demjenigen, der es schaffen würde, den Algorithmus um 10 Prozent zu verbessern, 1 Million Dollar. (http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html)

Letztendlich gewann ein Team, das eine Verbesserung von 8,43% geschafft hat. Das Team habe 2000 Stunden Arbeit damit verbracht, um einen Kombination aus 107 Algorithmen zu präsentieren.
Um den Algorithmus einsetzen zu können, mussten einige Anpassungen vorgenommen werden. So konnte beispielweise der ursprüngliche Algorithmus nicht mehr als 100 Millionen Bewertungen händeln, wobei zu dem Zeitpunkt bereits 5 Milliarden Bewertungen vorhanden waren.
In 2012 wurden bereits 75% der Filme und Serien aufgrund des Empfehlungssystems geschaut.


## 3.1.2 Speicherung / Algorithmus

In Anbetracht der Tatsache, dass Netflix mehr als 85 Millionen Abonnenten hat (Stand von Oktober 2016 laut http://www.wiwo.de/unternehmen/it/netflix-in-deutschland-mehr-abonnenten-als-einwohner/14702184.html), wird klar, dass sie ein riesiges Repertoire an “personalisierten Genres” haben.

In dem Artikel *How Netflix Reverse Engineered Hollywood* vom 02.01.2014 beschreibt das Magazin *The Atlantic* ihre Recherchearbeiten zum Algorithmus von Netflix.
Sie haben herausgefunden, dass Netflix zu diesem Zeitpunkt 76.897 Genres besitzt, um Filmtypen zu beschreiben. Zum heutigen Zeitpunkt sind es fast 93.000 (https://docs.google.com/spreadsheets/d/1eISFvq42Sll10xekyV-XQdwoG7_gjZpreNG40Pz8G0k/edit#gid=2125244376).

Zu den neuesten zählen Genres wie “Golden Globe Award-winning Understated Comedies” und “Critically-acclaimed Biographical Drug Documentaries”.

*The Atlantic* hat herausgefunden, dass Netflix jeden einzelnen denkbaren Film und jede Serie analysiert hat und sich somit eine enorme Datenbasis aufgebaut hat.
Dies gelang Ihnen, indem sie Menschen engagiert haben, die Filme schauen und diese mit unterschiedlichsten Metadaten beschreiben. Dazu gehören der Romantiklevel, wie blutrünstig ein Film ist und erzählerische Daten, wie zum Beispiel die Schlüssigkeit der Handlung.
Die ausgebildeten Filmeschauer bewerten dutzende von Eigenschaften, darunter auch den Moralstatus der Charaktere. Diese Eigenschaften werden mit den Gewohnheiten der Netflix User kombiniert, woraus ein großer Wettbewerbsvorteil für Netflix entsteht.


![adjectives](./images/adjectives.png)  

Durch den Alghorithmus hat Netflix eine neue Form des Empfehlens geschaffen.

### 3.1.2.1 Kollaboratives Filtern
http://inka.htw-berlin.de/Sieck/Abschlussarbeiten/Hebeisen.pdf

Die am häufigsten verbreitete Filtermethode für Empfehlungssysteme ist heutzutage das kollaborative Filtern. Ein kollaboratives System ist ein lernendes System, welches eine vorhandene Datenbasis nutzt. Anhand dieser Datenbasis sollen Verhaltensmuster von Nutzereingaben zu erkennen sein und es soll versucht werden, eine Verbindung zwischen eingegebenen und bereits vorhandenen Daten herzustellen (User-to-User). Es werden also Empfehlungen auf Basis von Bewertungen anderer Nutzer gegeben. Das Interessenprofil eines Nutzers soll auf das Interessenprofil eines anderen Nutzers übertragen werden. Bewertungen erfolgen hierbei entweder durch konkrete Bewertungen einer bestimmten Sache (zum Beispiel eines Filmes), indem beispielsweise anhand einer Skala ein Rating abgegeben wird oder angegeben wird, ob etwas nützlich war, oder aber auch durch das implizite Verhalten des Nutzers. Hierbei wird zum Beispiel berückstichtigt, wie lange ein Nutzer etwas angeschaut hat oder was angeschaut wurde.
Beim kollaborativen Filtern wird davon ausgegangen, dass man ein statistischer Nachbar ist, wenn man ähnliche Bewertungen abgegeben hat und dass etwas für einen Nutzer relevant oder interessant ist, wenn es auch für den statistischen Nachbarn interessant war.
Wenn Anna zum Beispiel Film 1 mit 3 Sternen, Film 3 mit 4 Sternen und Film 5 mit 2 Sternen bewertet hat und Julia Film 1 mit 2 Sternen, Film 3 mit 5 Sternen, Film 4 mit 4 Sternen und Film 5 mit 1 Stern bewertet hat, dann scheinen die beiden Benutzer Anna und Julia ähnlich zu sein. Anna kann also nach der kollaborativen Filtertechnik der Film 4 vorgeschlagen werden, den sie ja noch nicht gesehen hat, da ihre statistische Nachbarin Julia diesen Film interessant fand, bzw. ausreichend gut bewertet hat.

![kollaboratives Filtern](./images/kollaborativesFiltern.png)  

Bei dem kollaborativen Empfehlungssystem wurde versucht vorherzusagen, wie viele Sterne man einem Film geben würde. Dafür musste man möglichst viele Filme bewerten, um daraus überhaupt eine Tendenz und ein Profil des Nutzers erstellen zu können.

Das Hauptproblem von kollaborativen Empfehlungssystemen ist dementsprechend das Fehlen einer Datenbasis. Neue Nutzer haben noch keine Bewertungen abgegeben und haben somit auch keine statistischen Nachbarn. Selbes gilt auch für die Objekte, die einem System neu hinzugefügt werden. Wird also beispielweise ein Film neu hinzugefügt, hat er zu Beginn keine Bewertungen und kann somit nicht bei der Technik des kollaborativen Filtern berückstichtigt werden.

### 3.1.2.2 Inhaltsbasiertes Filtern

Eine andere Filtermethode ist das inhaltsbasierte Filtern. Hier werden Empfehlungen anhand von Ähnlichkeiten von Objekten oder Nutzerprofilen generiert. Die Objekte werden hierbei durch ihre Inhalte oder durch Eigenschaften und Metadaten beschrieben. Anders als beim kollaborativen Filtern wird hier nicht versucht, eine Verbindung zwischen mehreren Nutzern herzustellen, sondern es wird versucht, eine Verbindung zwischen mehreren Objekten herzustellen (Item-to-Item). Ein Nutzerprofil beinhaltet Interessen über Objekt-Attribute, die zum einen durch direkte Eingabe oder durch implizites Nutzungsverhalten (zum Beispiel der Analyse der Tätigkeiten des Nutzers) gesammelt werden. Empfehlungen werden ausgesprochen, wenn eine nahe Verbindung zwischen Nutzerpräferenzen und Objekteigenschaft besteht.

### 3.1.2.3 Algorithmus von Netflix
Eine Aussage im Atlantic Artikel besagt, dass Netflix ein System gebaut habe, welches wirklich nur mit einem in der Technologie-Welt vergleichbar ist, und zwar dem NewsFeed von Facebook. 


## 3.1.3 Analyse der Daten

Um Schlussfolgerungen aus Datenerhebungen zu ziehen, muss zuerst eine gewisse Menge an Daten zur Analyse bereit stehen.
Erst wenn genug Menschen beispielsweise an einer bestimmten Stelle Pause gedrückt oder vorgespult haben, kann man anfangen, Schlussfolgerungen aus diesem Verhalten zu ziehen.
Wenn ständig an der gleichen Stelle Pause gedrückt wird, könnte die Handlung zu langwierig oder langweilig geworden sein um das Interesse der Zuschauer zu halten. Es könnte auch sein, dass der Plot zu kompliziert wurde. Wenn genug Nutzer nach der Pause nie weiter schauen, könnte die Annahme getroffen werden, dass die Sendung schlecht ist.
Natürlich sind das alles aber nur Annahmen. Trotz der gigantischen gesammelten Datenmenge kann Netflix nicht mit 100%iger Sicherheit sagen, was dieses Verhalten der User bedeutet.

Aufgezeichnet werden alle erdenklichen Daten, von Standort des Nutzers, Gerät des Nutzers, Uhrzeit am Nutzungsort, Dauer der Nutzung, in welcher Sprache geschaut wird, ob ganze Folgen/Filme schaut werden oder ob abgebrochen wird, wann und wie lange pausiert wird, ob vorgespult wird, wann gestoppt wird und was geschaut wird natürlich, gespeichert. Außerdem werden die Ratings, die Likes, die geteilten Inhalte sowie die Interaktionen, wie Scrollen, Sucheingaben und das Hinzufügen zu Listen gespeichert.
Zum Einen weiß Netflix durch die Analyse dieser Daten, welche Schauspieler und welche Genres bevorzugt werden. Zum Anderen kann so aber auch herausgefunden werden, ob am Wochenende eher Serien oder eher Filme geschaut werden. Dies wird dann bei den nächsten Empfehlungen berücksichtigt und es wird mehr von den favorisierten Formaten vorgeschlagen.


## 3.1.4 Nutzung der Daten 

Laut Salon arbeitet Netflix seit 2012 daran, insofern Nutzen aus ihrer Big Date Kapazität zu ziehen, als dass sie versuchen damit ihre Programmauswahl zu beeinflussen. Konkret bedeutet es, dass sie Serien aufgrund ihrere Analyseergebnisse kaufen oder produzieren.
Das Pilot-Projekt dieser Strategie ist die Serie *House Of Cards*. *House Of Cards* war ursprünglich eine britische Miniserie, die 1990 auf dem britischen Kanal BBC ausgestrahlt wurde. Die Serie bestand nur aus vier Episoden und handelt von einem Politiker, der zusammen mit seiner Ehefrau Rachepläne ausübt, nachdem er vom Premierminister hintergangen wurde.

Aufgrund der Big Data-Analyse von Netflix wurde die Entscheidung getroffen, eine Neuauflage der britischen Serie *House Of Cards* zu produzieren.
Den Analyseergebnissen konnte man entnehmen, dass dieselben Personen, die das britische Original von *House Of Cards* liebten, ebenfalls Filme lieben, bei denen Kevin Spacey mitspielt oder die unter der Regie von David Fincher entstanden sind.

Die Argumente waren also:
- Die britische Version von *House of Cards* hatte ein großes Publikum,
- *The Social Network*, bei dem David Fincher Regie geführt hat, hatte ein großes Publikum,
- Nutzer, die die britische Version von *House Of Cards* geschaut haben, schauten oft auch Filme mit Kevin Spacey und/oder Filme, die unter der Regie von David Fincher entstanden sind.

Somit sollte das Remake der Serie, die für 13 Episoden 100 Millionen Dollar gekostet hat, ein Kinderspiel werden.

Verglichen zu traditionellen Studios, die außer den verkauften Tickets und DVDs kein Feedback ihrer Kunden bekommen, ist Netflix, was das Feedback und die Analyse angeht, Welten voraus. Netflix kann viel schneller handeln als die traditionelle Konkurrenz. Netflix muss vor der Produktion eines Film oder einer Serie nicht mehr ahnen, was die Nutzer sehen wollen, sondern stützt sich auf ihre Analysen. Sie können die Daten sogar bis auf die Postleitzahl herunterbrechen und herausfinden, welche Shows mit welchen Schauspielern die Nutzer in bestimmten Regionen am liebsten sehen.

Die traditionellen Studios haben einen großen Nachteil. Einer der größten Posten bei den Kosten einer Filmproduktion ist das Marketing. Es gibt aber keine Möglichkeit herauszufinden, welche der Marketingstragien erfolreich waren und welche nicht und ob es das Marketing überhaupt etwas bringt. Es können auch Millionen ins Marketing fließen und der Film wird trotzdem ein Flop.

Die Nutzer von Netflix entscheiden durch ihr Nutzungsverhalten, was produziert wird und was nicht. Ebenso legen sie fest, welche Schauspieler sie sehen wollen. Netflix hat es geschafft, eine Brücke zwischen Nutzern und Produzenten zu bauen. Das Team, das entscheidet, was produziert wird, kann sich ganz einfach an den Daten der Nutzer orientieren.

## 3.1.5 Visualisierung


Die Darstellung einzelner Sendungen hängt nicht vom Zufall ab. Ganz im Gegenteil: Die Platzierung und Auswahl der richtigen Sendungen für die einzelnen Zeilen ist ein wichtiger Teil des Personalisierungsansatzes von Netflix. Es muss also herausgefunden werden, welche Zeilen am relevantesten für jeden einzelnen Nutzer sind sowie mit welchen Sendungen die Zeilen gefüllt werden. Außerdem muss entschieden werden, an welcher Stelle der limitierten Startseite jede Zeile platziert wird, so dass die Auswahl des nächsten Videos intuitiv geschehen wird.

Hierfür nutzt Neflix das maschinelle Lernen. Die Maschine lernt, historische Informationen zu nutzen. Historische Informationen wären zum Beispiel:
+ welche Homepages wurden für die Mitglieder erstellt
+ wie interagieren die Mitglieder
+ was schauen die Mitglieder tatsächlich gerade an
+ was spielen sie überhaupt ab

Es gibt offenbar einige Herausforderungen für das Anlernen des Modells für maschinelles Lernen. Die Trainingsdaten für den Algorithmus müssen sehr bedacht ausgewählt werden. Die Herausforderung ist auch, wie die Zuordnung im Modell erlaubt ist. Wenn ein Nutzer ein Video aus einer bestimmten Zeile in der Vergangenheit abgespielt hat, heißt es nicht, dass der Nutzer dieses Video ebenfalls ausgewählt hätte, wenn es in einer anderen Zeile an erster Stelle gestanden hätte. Es könnte die Benennung der Zeile und nicht die Postition in der Zeile ausschlaggebend für das Abspielen gewesen sein. Ebenso herausfordernd kann das Lernen der Merkmale um Vielfalt darzustellen sein. Vor allem, wenn der Platz für potentielle Zeilen an unterschiedlichen Stellen groß ist, wenn der Rest der Seite (oder die bereits vergebenen Zeilen) für die Vielfalt berücksichtigt wird, ist der Platz für mögliche Seiten noch größer.

Um diese Herausforderungen zu bewältigen, ist es wichtig, eine gute Metrik auszuwählen. Von hoher Wichtigkeit für die Seitengenerierung ist, wie die Qualität der Seiten, die durch einen Algorithmus erzeugt wurden, zu bewerten ist. Jede mögliche Verbesserung des Algorithmus' wird sofort online in einem A/B-Test geprüft. Netflx möchte in der Lage sein, die wertvollen A/B-Testressourcen auf Algorithmen anzuwenden, von denen angenommen wird, dass sie die Qualität der Seiten wahrscheinlich verbessern. Die Parameter der Algorithmen sollte vor dem A/B-Test abgestimmt werden. Dazu können historische Daten verwendet werden, um hypothetische Seiten aus dem neuen algorithmischen Ansatz zu generieren.

Um sich Qualitätsmetriken auf Seitenebene auszudenken, hat sich Netflix von Rang-Metriken, die in der Informationsrückgewinnung inspirieren lassen.
TODO

http://techblog.netflix.com/2016/10/to-be-continued.html
Das Ziel des Empfehlungssystem von Netflix ist, die perfekte Serie oder den perfekten Film für jeden Nutzer zu kennen und diesen direkt beim Start von Netflix zu starten.
Wenn ein Nutzer Netflix öffnet, möchte er entweder eine ganz neue, für ihn unbekannte Show entdecken oder die nächste Folge einer bereits bekannten Serie sehen, bzw. einen angefangenen Film zuende schauen. Wenn Netflix vorhersagen kann, dass der Nutzer beim Öffnen gerade eine Serie oder einen Film weiterschauen möchte, so würde es Sinn machen, diese Show an präsenter Stelle auf der Startseite zu platzieren.
Grundsätzlich fokussiert Netflix sich hier auf die Zeile "Weiterschauen". Ein nicht unerheblicher Anteil der Streaming-Zeit erfolgt aufgrund der Platzierung der Serie oder des Films in dieser Zeile.
Wie die Zeile auf der Seite platziert wurde, hing von einigen Regeln ab, die wiederum vom der Plattform abhängig waren. In dem Artikel *To Be Continued: Helping you find shows to continue watching on Netflix* erklärt Netflix, sie wollen dies nun über die Plattformen hinweg vereinheitlichen um die Nutzererfahrung der "Weiterschauen"-Zeile anhand folgender zweier Dimensionen zu verbessern:
+ Verbesserung der Platzierung der Zeile: Sie soll höher platziert werden, wenn ein Nutzer im "Weiterschauen-Modus" ist. Sie soll tiefer platziert werden, wenn ein Nutzer eher nach einem neuen Titel sucht, sich also im "Entdeckungs-Modus" befindet.
+ Verbesserung der Reihenfolge der zuletzt angeschauten Shows in der Zeile in Abhängigkeit der Wahrscheinlichkeit, dass sie beim nächsten Aufruf von Netflix angeschaut/weitergeschaut werden.

Herauszufinden, wie hoch die Wahrscheinlichkeit ist, dass sich ein Nutzer gerade im "Weiterschauen-Modus" befindet, versucht Netflix über die Definition unterschiedlicher Aktivitätsmuster.
Ein Nutzer ist möglicherweise gewollt, eine Show fortzusetzen, wenn er:
+ schon viele Folgen einer Serie geschaut hat, diese aber noch nicht komplett zuende geschaut hat
+ vor Kurzem einen Film angefangen hat
+ eine Show vermehrt zu einer bestimmten Zeit am Tag oder über das aktuelle Gerät geschaut hat

Im "Entdeckungs-Modus" befindet sich der Nutzer eher, wenn er:
+ gerade einen Film zu Ende oder alle Staffeln und Episoden einer Serie geschaut hat
+ in letzter Zeit nichts mehr geschaut hat
+ sich neu bei Netflix angemeldet hat

Diese Hypothesen haben Netflix laut oben genanntem Artikel dazu motiviert, ein maschinenlernendes Modell zu bauen, welches obige Muster identifiziert und nutzt, um eine bessere "Weiterschauen"-Zeile zu generieren.

Um ein Empfehlungsmodell für die "Weiterschauen"-Zeile zu kreiren, braucht man zunächst Merkmale, die Muster aus dem Verhalten der Nutzer erkennen. Diese sollen dabei helfen, eine Vorhersage zu treffen, wann ein Nutzer eine Serie oder einen Film weitersehen möchte. Diese Merkmale werden als Input für das Erstellen des maschinenlernenden Modells. Die wichtigsten Merkmale können dann später nach einigen Testläufen optimiert und ausgewählt werden.

Im Artikel des Netflix Blogs haben die Autoren drei mögliche Ideen für das Erstellen des Weiterschauen-Modells berücksichtigt, darunter:
A. Eigenschaften auf Mitgliedsebene:
    + Daten über das Abonnement des Mitglieds, wie zum Beispiel die Dauer des Abonnements, das Land der Registrierung und die Sprachpräferenzen
    + Wie aktiv das Mitglied in letzter Zeit war
    + Die letzten Bewertungen des Mitglieds sowie Präferenzen in Genres

B. Eigenschaften über eine Sendung sowie die Interaktion des Nutzers mit dieser:
    + Wie lange ist es her, dass eine Sendung zu dem Katalog hinzugefügt, bzw. vom Mitglied geschaut wurde
    + Wie viel der Sendung hat das Mitglied geschaut
    + Metadaten über die Sendung, wie zum Beispiel Typ, Genre, Anzahl der Episoden. Beipsielsweise werden Kindersendungen öfert wiederholt geschaut
    + Beliebtheit und Relevanz der Sendung für das Mitglied
    + Wie oft das Mitglied die Sendung weitergeschaut hat

C. Kontextbezogene Eigenschaften:
    + Aktuelle Uhrzeit sowie Wochentag
    + Standort
    + Genutztes Gerät des Mitglieds

Für die optimale Darstellung der "Weiterschauen"-Zeile gibt es zwei Aufgaben: Sortierung der Ergebnisse innerhalb der Zeile sowie die Platzierung der Ergebnisse an eine sinnvolle Stelle auf der Startseite des Mitglieds.

Für die Sortierung der Ergebnisse innerhalb der "Weiterschauen"-Zeile hat Netflix ein Modell trainiert, das Sessions nutzt, in denen das Mitglied eine zuvor angesehene Sendung weiterschaut. In jeder Session lernt das Modell zwischen den Sendungen, die wiederholt werden, zu unterscheiden und ordnet diese in der vorhergesagten Wahrscheinlichkeit an.

Um die "Weiterschauen"-Zeile sinnvoll, bzw. an einer geeigneten Stelle auf der Startseite des Mitglieds zu platzieren, möchte Netflix die Wahrscheinlichkeit abschätzen, ob sich das Mitglied gerade im "Weiterschauen-Modus" oder aber im "Entdeckungs-Modus" befindet, so die Autoren des Blog Posts.
Aufgrund dieser Wahrscheinlichkeit könnten mehrere Ansätze verfolgt werden. Ein einfacher Ansatz wäre, dass es nur zwei Möglichkeiten gibt, die Zeile zu platzieren: oben auf der Seite oder weiter unten auf der Seite.
Durch Anwendung eines Schwellenwertes auf die vorhergesehene Wahrscheinlichkeit kann Netflix entscheiden, in welcher dieser beiden möglichen Positionen die Zeile platziert wird. Ein anderer Ansatz wäre, die Wahrscheinlichkeit auf verschiedene Positionen abzubilden.

## 3.1.6 Andere Anbieter:
Amazon Prime, Snap von Sky, Maxdome, Videoload, Watchever

http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html</Text>
        </Document>
        <Document ID="25">
            <Title>Notes</Title>
        </Document>
        <Document ID="10">
            <Title>Body</Title>
        </Document>
        <Document ID="48">
            <Title>5 Fazit</Title>
            <Text>Es ist schwer einem global agierenden Unternehmen in die Karten zu schauen. Alle Informationen die sich finden lassen geben zwar einen Überblick jedoch keinen direkten Einblick. Glücklicherweise ist das wohlgeplante teilen von Informationen mittlerweile Teil einer Corporate Identity womit wir zumindest etwas an der Oberfläche dieser Themen kratzen konnten. Wir hoffen dennoch wir konnten dem geneigten Leser etwas Wissenszuwachs bescheren. 

Karina Ennenga &amp; Fabian Morón Zirfas</Text>
        </Document>
        <Document ID="33">
            <Title>3.2 Cambridge Analytica</Title>
            <Text>Zum Grauen vieler zog zu Beginn des Dezembers 2016 ein Artikel mit dem Titel „Ich habe nur gezeigt, dass es die Bombe gibt“ seine Runde durch die verschiedensten „Sozialen Medien“. In ihm wird erläutert wie die psychologische Methode des Abgleichens von Facebook Daten mit Psychometrie Umfragen, entworfen von Michal Kosinski et. Al., im großen Stil mit öffentlich und zugänglich oder erwerbbare Daten von der Firma [„Cambridge Analytica“ (CA)](https://cambridgeanalytica.org/) genutzt wurden, um Donald Trump zum Sieg über Hillary Clinton in den Präsidentschaftswahlen der U.S.A. von 2016 zu verhelfen. Diese Methode soll es ermöglicht haben Personen so genau zu kategorisieren, dass Werbespots auf ihre persönlichen Ängste, Wünsche und politische Haltungen zurechtgeschnitten werden konnten. Der extrovertierte Unterstützer der National Rifle Association (NRA) bekommt Werbung für den Erhalt von Werten, die seit Generationen von Vater zu Sohn weitergegeben wurden, wohingegen die introvertierte Mutter durch Angst vor Terroristen zum Wählen des Kandidaten animiert werden soll. Ob dies wirklich eins zu eins so stattfand soll an dieser Stelle bezweifelt werden. Es gibt einige Tatsachen die dagegen sprechen. So ist ein Artikel, dessen gesamte Beweisführung sich auf die Aussagen von zwei Personen stützt, von denen eine noch ein großes Interesse daran hat genau so wahrgenommen zu werden, wenig fundiert. Ebenfalls trifft der Artikel einen bestimmten Nerv, schlägt genau in die richtige Kerbe zum richtigen Zeitpunkt. Nach einem langen und schmutzigen US-Wahlkampf, gewinnt __der von dem es die wenigsten geglaubt hätten__. Da ist es nur recht und billig einen Sündenbock zu finden. Nicht soziale Spannung, die wir uns nicht vorstellen können waren es, es muss eine neue bisher unbekannte Technologie _(vielleicht eine künstliche Intelligenz?)_ gewesen sein und irgendwie spielen unsere Daten die Facebook über uns sammelt da mit. Siehe WDR Blog, Spiegel Online, wired.com, bloomberg.com oder spektrum.de.   
Dennoch erweckt dies so sehr die Aufmerksamkeit der Autoren, dass hier einmal die Methoden und der Technologie Stack dieser Firma so weit es geht unter die Lupe genommen werden soll. Ebenfalls möchten wir auf die Möglichkeiten oder Gefahren, das liegt im Auge des Betrachters, die mit zielgerichteter Wahlwerbung vor uns stehen, aufmerksam machen. Als weiterführende Literatur empfehlen wir die Artikel „Algorithmen Allmächtig? Freiheit in den Zeiten der Statistik“ und „Parteien in Deutschland haben noch keine Position zu Wähler-Targeting“.  </Text>
            <Comments>Von Hannes Grassegger Und Mikael Krogerus. "Ich habe nur gezeigt, dass es die Bombe gibt - Das Magazin." Das Magazin. 3 Dec. 2016. Web. 8 Jan. 2017. &lt;https://www.dasmagazin.ch/2016/12/03/ich-habe-nur-gezeigt-dass-es-die-bombe-gibt/&gt;
Horn, Dennis. "Hat wirklich der große Big-Data-Zauber Trump zum Präsidenten gemacht?." Digitalistan. 5 Dec. 2016. Web. 9 Jan. 2017. &lt;https://blog.wdr.de/digitalistan/hat-wirklich-der-grosse-big-data-zauber-trump-zum-praesidenten-gemacht/&gt;
Spiegel Online, Hamburg, Germany. "US-Wahl und Daten-Ingenieure: Ich ganz allein habe Trump ins Amt gebracht - SPIEGEL ONLINE - Netzwelt." SPIEGEL ONLINE. 5 Dec. 2016. Web. 9 Jan. 2017. &lt;http://www.spiegel.de/netzwelt/netzpolitik/donald-trump-und-die-daten-ingenieure-endlich-eine-erklaerung-mit-der-alles-sinn-ergibt-a-1124439.html&gt;
Issie Lapowsky. "A Lot of People Are Saying Trump’s New Data Team Is Shady." WIRED. 15 Aug. 2016. Web. 9 Jan. 2017. &lt;https://www.wired.com/2016/08/trump-cambridge-analytica/&gt;
Bershidsky, Leonid. "No, Big Data Didn't Win the U.S. Election." Bloomberg View. 8 Dec. 2016. Web. 9 Jan. 2017. &lt;https://www.bloomberg.com/view/articles/2016-12-08/no-big-data-didn-t-win-the-u-s-election&gt;
Eva Wolfangel. "Big Data: Haben psychologische Facebookdaten Trumps Sieg verursacht?." Spektrum.de. n.d. Web. 9 Jan. 2017. &lt;http://www.spektrum.de/kolumne/haben-psychologische-facebookdaten-trumps-sieg-verursacht/1431745&gt;
Gastbeitrag. "Algorithmen Allmächtig? Freiheit in den Zeiten der Statistik." netzpolitik.org. 25 Jul. 2014. Web. 25 Jan. 2017. &lt;https://netzpolitik.org/2014/algorithmen-allmaechtig-freiheit-in-den-zeiten-der-statistik/&gt;
Markus Reuter. "Parteien in Deutschland haben noch keine Position zu Wähler-Targeting (Update)." netzpolitik.org. 6 Dec. 2016. Web. 25 Jan. 2017. &lt;https://netzpolitik.org/2016/parteien-in-deutschland-haben-noch-keine-position-zu-waehler-targeting/&gt;</Comments>
        </Document>
        <Document ID="26">
            <Title>Example Essay</Title>
            <Text>Sarah Tu Dent Professor Krowes Philosophy of Whales 101 November 1, 2010
String Theory, Time and Tralfamadore Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean laoreet posuere est, in
consequat est imperdiet nec. Morbi vel orci mattis erat mattis vulputate vel nec eros. Sed at mauris tortor, nec ornare erat. Praesent felis velit, dapibus at pretium non, congue sed ligula. Nam ac gravida nunc. Nam sapien lectus, pellentesque pharetra semper eu, rutrum nec neque.
This is a block quote - it is indented from the main text. Praesent purus orci, ornare et luctus quis, iaculis eu dolor. Proin ornare sodales semper. Sed aliquet, orci at volutpat tristique, justo mi condimentum velit, ac feugiat ipsum nulla eget leo. Integer purus sem, placerat nec lacinia vel, mollis vitae magna. In hac habitasse platea dictumst. Vivamus sed elit augue, a consequat dolor. Proin at elementum tellus. Donec sodales, turpis sit amet porta ornare, nisi diam fringilla erat, eget varius lorem lectus eget tortor. Etiam eros nisl, gravida eu eleifend eu, semper non nulla. Pellentesque semper laoreet volutpat. Nam ac malesuada metus. Nunc ut eros est, nec accumsan est.
Vivamus porta auctor arcu eu scelerisque. Donec fringilla blandit ligula at laoreet. Cras lobortis est velit, in cursus erat. Donec convallis fermentum tortor, ut interdum ligula facilisis at. Nam posuere felis nec libero lobortis vitae porta est vulputate. Proin massa metus, condimentum vitae venenatis vel, sodales eu dolor. Suspendisse potenti. Nullam congue ipsum ac turpis scelerisque vehicula. Nunc ipsum odio, consequat eget laoreet quis, semper ut dolor.1
Dent 1
Aliquam vulputate, odio ultrices accumsan vulputate, sem augue feugiat dolor, mattis aliquam erat libero a tortor. Etiam sagittis felis ullamcorper nunc fringilla nec viverra libero varius. Morbi volutpat auctor justo vestibulum bibendum. Cras nec nulla sit amet massa commodo aliquam. Quisque euismod dapibus ante quis lacinia. Praesent tempus dolor a libero sollicitudin quis consectetur ipsum bibendum. Donec pretium tincidunt odio, eu aliquet leo varius eu. Praesent euismod enim accumsan dui aliquet commodo. Nulla posuere, velit lacinia venenatis semper, sapien lacus aliquet lorem, in laoreet dolor lacus in arcu.
Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Donec varius, sapien sit amet malesuada ultrices, dui sem tincidunt urna, at varius sapien libero sed ipsum. Suspendisse dolor mauris, auctor a volutpat feugiat, facilisis ac magna. Nullam metus nisl, ultricies sed laoreet nec, posuere vitae magna.
Sed vitae mauris non dui scelerisque lobortis ut sed risus. Aliquam erat volutpat. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Ut semper lacinia velit in ultricies. Mauris id quam enim, quis dapibus nisi. Fusce ipsum urna, lacinia sit amet euismod nec, mollis dapibus ligula. Fusce dolor nunc,
auctor sit amet pharetra vel, porta et elit. Nam eget velit neque. Donec varius eros vitae quam viverra pulvinar.
Duis est elit, dictum nec vestibulum non, ultrices ut massa. Suspendisse egestas vehicula justo, tempus mattis ipsum scelerisque sed. Vestibulum interdum porta risus, nec tristique sem feugiat eget. Vivamus a venenatis risus. Quisque ligula augue, euismod ac convallis vel, sagittis dapibus leo. Donec eleifend urna vitae eros mollis nec venenatis purus commodo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Proin eu sapien vitae
Dent 2
arcu euismod pharetra et id arcu.2 Sed lectus urna, mattis a gravida ut, sollicitudin id tortor. Maecenas et mi justo, eget
dictum arcu. Praesent felis nunc, tempus egestas bibendum sit amet, dictum id eros. Integer purus velit, aliquam placerat vehicula at, sodales in erat. Vestibulum at neque vitae orci convallis consectetur a at sapien. Nulla id consequat elit. Suspendisse potenti. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Etiam sagittis dapibus mauris a aliquet. Ut lorem ipsum, blandit nec eleifend cursus, pharetra ut elit.
Proin semper porta diam, id rutrum orci facilisis ac. Morbi blandit erat augue, et vulputate metus. Vestibulum non arcu felis, nec bibendum neque. Ut at odio velit. Aenean consectetur
dapibus sollicitudin. Suspendisse potenti. Nam fermentum risus in odio sollicitudin interdum. Donec quam orci, commodo eget consectetur id, varius egestas magna. Morbi tincidunt fermentum orci ac imperdiet. Aliquam hendrerit lorem ac urna elementum fermentum. Aenean sollicitudin ipsum vitae arcu malesuada tempor. Phasellus feugiat dignissim erat non lobortis. Pellentesque at est at nisl fringilla posuere. Proin sagittis cursus nunc eget commodo. Nulla feugiat vehicula scelerisque. Nam quam neque, ornare sit amet tincidunt in, interdum sed nibh. Cras eget est sit amet diam adipiscing lacinia et at nisl. Nullam vulputate aliquam lorem at ultrices.
Vivamus sit amet orci turpis. Nunc pretium cursus augue vel lacinia. Aliquam vulputate, odio ultrices accumsan vulputate, sem augue feugiat dolor, mattis aliquam erat libero a tortor. Etiam sagittis felis ullamcorper nunc fringilla nec viverra libero varius. Morbi volutpat auctor justo vestibulum bibendum. Cras nec nulla sit amet massa commodo aliquam. Quisque euismod
Dent 3
dapibus ante quis lacinia. Praesent tempus dolor a libero sollicitudin quis consectetur ipsum bibendum. Donec pretium tincidunt odio, eu aliquet leo varius eu. Praesent euismod enim accumsan dui aliquet commodo. Nulla posuere, velit lacinia venenatis semper, sapien lacus aliquet lorem, in laoreet dolor lacus in arcu.
Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.3 Donec varius, sapien sit amet malesuada ultrices, dui sem tincidunt urna, at varius sapien libero sed ipsum. Suspendisse dolor mauris, auctor a volutpat feugiat, facilisis ac magna. Nullam metus nisl, ultricies sed laoreet nec, posuere vitae magna. Sed vitae mauris non dui scelerisque lobortis ut sed risus. Aliquam erat volutpat. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Ut semper lacinia velit in ultricies. Mauris id quam enim, quis dapibus nisi. Fusce ipsum urna, lacinia sit amet euismod nec, mollis dapibus ligula. Fusce dolor nunc, auctor sit amet pharetra vel, porta et elit. Nam eget velit neque. Donec varius eros vitae quam viverra pulvinar.
Dent 4
Notes 1 This endnote was added to the text as an inspector footnote, but gets moved to the endnotes
page during the compile process. 2 Yem thung jince ti rintax harle velar yiphras whik, xi lamax qi clum prinquis nalista arul ma su irpsa velar prinquis whik nalista dri teng twock tolaspa. 3 Rhull er wex twock athran zorl su clum qi helk gronk wynlarce kurnap, tharn brul tolaspa fli xu berot frimba flim teng ux wynlarce. Lydran anu er, su thung yiphras menardis wex xu erk ma irpsa re gra dwint velar re morvit wynlarce teng. Gronk tharn morvit, teng yem urfa ux clum, wex arka gra wynlarce su lamax zeuhl rintax.
Dent 5
Works Cited Adkinson, Stephen, and Stephen Tchudi. "Grading on Merit and Achievement: Where Quality
Meets Quantity." Alternatives to Grading Student Writing. Ed. Stephen Tchudi. Urbana, IL:
NCTE, 1998. 192-208. Print. Allender, Dale, Comp. “Trends and Issues in English Instruction.” Commissions of the National
Council of Teachers of English." (2000): 1-6. ERIC. Web. ED440392. 12 June 2006. Belanger, Joe. "Conflict between Mentor and Judge: Being Fair and Being Helpful in
Composition Evaluation." English Quarterly 18.4 (1985): 79-92. Print. Beck, Sarah. "Subjectivity and Intersubjectivity in Teaching and Learning of Writing." Research
in the Teaching of English 40.4 (2006): 413-60. Print. Braine, John. Writing A Novel. New York: McGraw-Hill, 1975. Broad, Bob. What We Really Value: Beyond Rubrics in Teaching and Assessing Writing. Salt
Lake City: Utah State UP, 2003. Print. Burke, Kenneth. The Philosophy of Literary Form. Third ed. Berkeley: U of California P, 1973.
Print. Chesterton, G. K. "The Mirror and the Magistrate." The University of Adelaidee. e-text library.
&lt;http://etext.library.adelaide.edu.au/c/chesterton/gk/c52fb/chapter34.html&gt;. n.d. Web. 19
May 2010. Connolly, Paul, and Teresa Vilardi. Writing to Learn Mathematics and Science. New York:
Teachers College Press (1989): 1-328. ERIC. ED 309997. Web. 19 May 2010. Danticat, Edwidge. Interviewed by Sarah Anne Johnson. Writers Ask 36 (2007): 13-14. Web. 19
May 2010. Print.
Dent 6
Elbow, Peter. "Ranking, Evaluating, and Liking: Sorting Out Three Forms of Judgment." College English 55.2 (1993): 187-206. Print.
Emerson, George H. "Revised System of Evaluation." Diss. Nova University (1974): 1-33. ERIC. Web. ED111465. 12 June 2006.
—-. A Contract For A Final Grade of B. Unpublished handout. n.d. Emig, Janet. “Writing as a Mode of Learning.” College Composition and Communication 28. 2
(1977): 122-28. "Ernest Hemingway." BrainyQuote.com. Xplore Inc, 2010. 1 October. 2010. Web. 30 Sept. 2010.
&lt;http://www.brainyquote.com/quotes/quotes/e/ernesthemi152953.html&gt; Feinstein, Sascha. Personal Interview. 8 April 2007. Fowler, Henry. A Dictionary of Modern English Usage. 1926. Oxford Language Classics Series.
Oxford: Oxford UP, 2003. Print. Fulwiler, Toby. "The Argument for Writing Across the Curriculum." Writing Across the
Disciplines: Research into Practice. Ed. Art Young and Toby Fulwiler. Upper Montclair,
NJ: Boynton/Cook, 1986. 21-32. Print. Glasser, William. Schools without Failure. New York: Harper, 1968. Print. Glater, Jonathan D. "To: Professor@University.Edu Subject: Why It's All About Me." New York
Times 22 February 2006, Washington ed., sec. A:1. Print. Hansen, Kristine et al. "Are Advanced Placement English and First-Year College Composition
Equivalent? A Comparison of Outcomes in the Writing of Three Groups of Sophomore
College Students." RTE 40.4 (2006): 461-501. Print. Hawkes, G. W. Personal interview. 10 April 2006.
Dent 7
Helprin, Mark. Digital Barbarism: A Writer’s Manifesto. New York: Harper, 2009. Print. Hillocks, George, Jr. "A Response to Professor Livatino." Writing on the Edge 17.2 (2007):
59-60. MLA International Bibliography. JSTOR. Web. 6 May 2010. ---. Research on Written Composition: New Directions for Teaching. Urbana, IL: National
Conference on Research in English and Educational Resources Information Center, 1986.
Print. Kolln, Martha, and Craig Hancock. “The Story of English Grammar in United States Schools.”
English Teaching: Practice and Critique 4.3 (2005): 11-31. Print. Kohn, Alfie. The Schools Our Children Deserve: Moving Beyond Traditional Classrooms and
"Tougher Standards." New York: Houghton Mifflin, 1999. Print. —-. "The Trouble with Rubrics." English Journal 95.4 (2006): 12-15. Print. Kroll, Barry M. "How College Freshmen View Plagiarism." Written Communication. 5.2 (1988):
203-221. Print. Loux, Ann Kimble, and Rebecca Stoddart. "Denial, Conflagration, Pride: Three Stages in the
Development of an Advanced Writing Requirement." Conference on College Composition and Communication, San Diego, CA, 31 March-3 April 1993: 1-21. ERIC. Web. ED361730. 12 June 2006.
Lunsford, Andrea. Lecture. Lycoming College. 20 January 2003. Marzano, Robert J. Transforming Classroom Grading. Alexandria, VA: Association for
Supervision and Curriculum Development, 2000. Print. Mauriello, Tracie. “State Panel Approves High School Exit Exam. Post-Gazette.com
[Pittsburgh]. Pittsburgh Post Gazette Co. 17 January 2008: n. pag. Web. 20 May 2010.
Dent 8
Meikle, Robert J. “Traditional Grade-Based Writing Evaluation and the Process Approach: Systems in Conflict.” Canada; British Columbia (1982): 1-29. ERIC. Web. 19 May 2010.
Mulroy, David. The War Against Grammar. Portsmouth: Boynton/Cook/Heinemann, 2003. Print. Murray, Donald. A Writer Teaches Writing. Boston: Heinle, 2004. National Council of Teachers of English. Writing Now. A Policy Research Brief produced by the
National Council of Teachers of English, 2008. Print. O'Hagan, Liesel K. "It's Broken—Fix It." Alternatives to Grading Student Writing. Ed. Stephen
Tchudi. Urbana, IL: NCTE, 1998. 1-13. Print. Pennsylvania State Education Association. “Board Approves Statewide High School Graduation
Tests.” &lt;http://www.psea.org/general.aspx?id=1390&gt;. n.d. Web. 19 May 2010. Polyanyi, Michael. Knowing and Being. Ed. Marjorie Grene. London: Routledge and Kegan
Paul, 1969. Print. Ravitch, Diane. The Death and Life of the Great American School System: How Testing and
Choice Are Undermining Education. New York: Basic, 2010. Print. See, Carolyn. Making a Literary Life. New York: Ballantine, 2003. Wagner, Eileen Nause. The Impact of Composition Grading on the Attitudes and Writing
Performance of Freshman English Students. Diss., University Mircofilms (1975): 1-146.
ERIC. Web. 12 June 2006. —-. When the Bookkeeping System Takes Over: The Effects of Grading Compositions on
Student Attitudes (1976): 1-16. Paper presented at the annual meeting of the Conference on College Composition and Communication, Philadelphia, 25-27 March, 1976. ERIC. Web. 19 May 2010.
Dent 9
Walvoord, Barbara, and Virginia Johnson Anderson. Effective Grading: A Tool for Learning and Assessment. San Francisco: Jossey-Bass, 1998. Print.
Wilson, Maja. Rethinking Rubrics in Writing Assessment. Portsmouth: Heinemann, 2006. Print. Waugh, Evelyn. Interviewed by Julian Jebb. “Art of Fiction 30” Paris Review 30 (1963): n.pag.
Web. 18 May 2010. Ziegler, Alan. The Writing Workshop Note Book: Notes on Creating and Workshopping. New
York: Soft Skull Press, 2007.
Dent 10
</Text>
        </Document>
        <Document ID="40">
            <Title>Fazit</Title>
        </Document>
        <Document ID="19">
            <Title>Note on MLA Guidelines</Title>
            <Text>GENERAL GUIDELINES
For full guidelines, you should of course refer to the MLA Handbook.

Citations
Some examples of how to cite sources in the body of the paper:
When the author’s name is in the sentence: 	Jeffrey Jones states that “good times they are a’coming” (89).
When the author’s name is not in the sentence: 	It has been stated that good times are coming (Jones 89).
When more than one work by the same author are cited: 	One assertion is that his back was “hairy” (Solo-Organa, That Hairy Thing 84) - so hirsute, in fact, that he was likened to “a walking carpet” (Solo-Organa, Second Fiddle to Chewbacca 189).
Two or more authors: 	The closed-universe theory has been called into question (Rifle and Hartley 346-69).
No author listed: 	The zoo was apparently enclosed in a large drape to emulate night (Tralfamadore in Focus 57).

Works Cited Page
All entries should be double-spaced and listed in alphabetical order by the author’s last name. If no author is given, base the order on the first word of the entry. All entries should have a hanging indent of half an inch (that is, the first line of each entry should be flush with the left margin, and subsequent lines should be indented by half an inch).

Online Resources
The following web resources were used in putting together this template. (Note that although some of the links below point to descriptions of older versions of the MLA format, this template is based on the 7th edition, from 2009.)

General Formatting Guidelines
http://owl.english.purdue.edu/owl/resource/747/01/
http://www.writinghelp-central.com/mla-format-rules.html
http://www.csus.edu/owl/index/mla/mla_format.htm

Citation Guidelines
http://www.swccd.edu/~library/Pdfs/MLA6thEd.pdf</Text>
        </Document>
        <Document ID="41">
            <Title>Meta-Data</Title>
        </Document>
        <Document ID="34">
            <Title>Ausblick</Title>
            <Synopsis>Wo wird uns Data Science hinführen</Synopsis>
        </Document>
        <Document ID="27">
            <Title>MLA Format Notes</Title>
        </Document>
        <Document ID="42">
            <Title>Cambridge Analytica-1</Title>
        </Document>
        <Document ID="35">
            <Title>05_Quellen</Title>
        </Document>
        <Document ID="28">
            <Title>Ideas</Title>
        </Document>
        <Document ID="43">
            <Title>3.2.1 Die Dienstleistung</Title>
            <Text>Nach eigenen Aussagen kann die Firma Cambrige Analytica hinzugezogen werden, um auf eine neue Weise Kontakt zu seinem Publikum aufzunehmen. Auf ihrer Website versprechen sie bis zu 5000 Daten Punkten pro Person (derzeit nur US Bürger) zu sammeln und deren Verhalten auf Grund von verschiedenen Modellen vorauszusagen. 

&gt; _5,000 data points per person_  
&gt; We collect up to 5,000 data points on over 220 million Americans, and use more than 100 data variables to model target audience groups and predict the behavior of like-minded people.

Laut Angaben von Alexander Nix (CEO CA) auf dem 2016 Concordia Summit, werden demographische Daten Verbraucher-Daten und Daten aus dem Bereich Lifestyle, von Unternehmen geliefert wie [acxiom](http://www.acxiom.com/), [infogroup](http://www.infogroup.com/), [Experian](http://www.experian.com/), [data trust](http://thedatatrust.com/), [Facebook](https://www.facebook.com/), [L2](http://www.l2political.com/), [Aristotle](http://aristotle.com/), GOP, MRI, [Nielsen](http://www.nielsen.com/), [Magellan strategies](http://magellanstrategies.com/) mit psychographischen Daten verbunden. Mit diesen Informationen sollen in unserem Fall Wähler gezielt angesprochen worden sein. In dem Artikel, der unsere Recherche angestossen hat, wird von personalisierter Wahlwerbung gesprochen die bei der „Vote Leave“ Kampagne für den Ausstieg von Gross Britannien aus der Europäischen Union, bei der Präsidentschaftswahl 2016 in den Vereinigten Staaten von Amerika, zuerst für Ted Cruz und dann für Donald Trump, eingesetzt wurde.</Text>
            <Comments>N.a. "Cambridge Analytica – About Us." Cambridgeanalytica.org. 10 Jan. 2017. Web. 15 Jan. 2017. &lt;https://cambridgeanalytica.org/about&gt;
YouTube. "The Power of Big Data and Psychographics." YouTube. 27 Sept. 2016. Web. 22 Jan. 2017. &lt;https://www.youtube.com/watch?v=n8Dd5aVXLCc&gt;</Comments>
        </Document>
        <Document ID="36">
            <Title>Cambridge Analytica</Title>
        </Document>
        <Document ID="3">
            <Title>Title</Title>
            <Text>---
title: "Daten Wissenschaft"
subtitle: "Datenbanken in Big Data. Welche Technologien kommen zum Einsatz?"
institute: ["Beuth Hochschule für Technik - University of Applied Sciences", "Fachhochschule Lübeck - University of Applied Sciences"]
tags: ["Big Data", "Data Science"]

author:
   - Karina Ennenga 
   - Fabian Morón Zirfas
---
&lt;$fullname&gt;
Nikolai Alex
Datenbanktechnologien (FHBSWF MIM 12 W16)
&lt;$longdate&gt;
&lt;$Projecttitle&gt;
## Inhalt

&lt;!-- toc --&gt;

</Text>
            <Notes>The &lt;$projecttitle&gt; and &lt;$fullname&gt; tags get replaced with the information set in Project &gt; Meta-Data Settings… &gt; Project Properties. You can edit those settings or just replace this text altogether.</Notes>
        </Document>
        <Document ID="29">
            <Title>1 Abstrakt</Title>
            <Synopsis>Kurze Zusammenfassung der Kapitel</Synopsis>
            <Text>In der folgende Arbeit setzen wir, die Autoren Karina Ennenga und Fabian Morón Zirfas für das Seminar Datenbanktechnologien (FHBSWF MIM 12 W16) betreut durch Nikolai Alex, uns mit „Data Science in der Anwendung “ auseinander. Im ersten Kapitel „Was ist Data Science?“ versuchen wir kurz zu umreißen was unter dem Titel Data Science zu verstehen ist und wo es sich von zum Beispiel Statistik abgrenzt. Im zweiten Kapitel „Data Science in der Anwendung“ und seinen Unterkapiteln  „Netflix“ und „Cambridge Analytica“ betrachten wir exemplarisch diese zwei Unternehmen, um anhand dieser darstellen zu können was Data Science für Firmen bedeutet. Dem folgt im dritten Kapitel ein kurzer „Ausblick“ in die Zukunft um im „Fazit“, dem vierten Kapitel, zu Enden. </Text>
        </Document>
        <Document ID="44">
            <Title>3.2.2 Der Technologie Stack</Title>
            <Text>Natürlich lässt eine Firma wie Cambridge Analytica sich nicht direkt in die Karten schauen. Daher mussten wir einen andere Weg finden, um eine Idee zu bekommen mit welchen Technologien bei CA gearbeitet wird. Unser Ansatz ist, dass sich aus den aktuellen Stellenangeboten der Firma ein ungefähre Schätzung möglich ist, welche Technologien dort in den Alltagsgebrauch gehören. Zum aktuellen Zeitpunkt wurden dort zwei Stellen ausgeschrieben aus denen wir Schlüsse ziehen konnten. Es gab ein Stellenangebot für Data Engineers und eines für Data Scientists auf ihrer Seite. Bei Datenbanken werden Erfahrungen und Fähigkeiten im Umgang mit MySQL und, aus dem Sektor der NoSQL Datenbanken, MongoDB erwünscht. MySQL ist eine Variante der „Structured Query Language“, die um 1995 von der Firma MySQL AB entworfen und unter einer GNU General Public License veröffentlicht wurde. NoSQL steht nicht für die Verneinung von SQL Datenbanken, sondern für „Not Only SQL“. Damit werden unterschiedliche Typen von Datenbanken bezeichnet wie zum Beispiel die von CA gewünschte MongoDB. Im Bereich Big Data scheinen die Frameworks Spark und Hadoop zum Einsatz zu kommen und die gewünschten Sprachen sind Python, Java oder Scala und entsprechenden „Objekt Orientierten Programmier Paradigmen“. Des weiteren natürlich der Umgang mit Versions Kontroll Systemen. Anhand dieser Punkte werden wir versuchen die verwendeten Technologien zu betrachten.   </Text>
            <Comments>Cambridge Analytica. "Cambridge Analytica – Better Audience Targeting." Cambridge Analytica. 10 Jan. 2017. Web. 22 Jan. 2017. &lt;https://cambridgeanalytica.org/&gt;</Comments>
        </Document>
        <Document ID="37">
            <Title>notes</Title>
            <Text>Notes  
=====

Lose Notizen die bei der Recherche zusammen kommen.  


&gt; data driven behaviour change  
&gt; [CA youtube promo video](https://youtu.be/vLFMGJyEwrA)  

---

Welche Typen von Daten werden von [Cambridge Analytica](https://cambridgeanalytica.org/) (CA) verwendet.  

Demographische, Konsumer und "Lifestyle" Daten werden verbunden mit psychographischen Daten.  
Quelle 2016 Concordia Summit, Alexander Nix, [youtube](https://www.youtube.com/watch?v=n8Dd5aVXLCc)  

| Demographics/Geographics (Factual) | Psychographics (Attitudinal)            |
| :--                                | :--                                     |
| Age                                | Advertising Resonance                   |
| Gender                             | Automotive Data                         |
| Ethnicity                          | Consumer Data                           |
| Religion                           | Consumer Confidence- Economy / Business |
| Education                          | Lifestyle Data                          |
| Income                             | Buying Styles/Patterns                  |
| Home-owner                         | Civic / Political Engagement Segments   |
| socio-economic status               | Cellular / Mobil Opinions               |
| Geographic factors                 | x                                       |

Firmen von denen Daten aggregiert werden: [acxiom](http://www.acxiom.com/), [infogroup](http://www.infogroup.com/), [Experian](http://www.experian.com/), [data trust](http://thedatatrust.com/), [Facebook](https://www.facebook.com/), [L2](http://www.l2political.com/), [Aristotle](http://aristotle.com/), GOP, MRI , [Nielsen](http://www.nielsen.com/), [Magellan strategies](http://magellanstrategies.com/)  

combined with   
- psyochgraphic data (modeling of personality)

Personality (Behavioral)
__Psychology:__ 
Openness
Conscientiousness
Extraversion
Agreeableness
Neuroticisrn


__Persuasion:__  
Reciprocity
Scarcity
Authority
Fear
Social Proof


---

https://de.wikipedia.org/wiki/Big_Five_(Psychologie)

---
CA Job offers

databases and data pipelines for storing and processing large, sometimes unstructured datasets for use with our analytics platform.  https://cambridgeanalytica.org/careers

Experience with both SQL (MySQL) and noSQL (MongoDB) databases 

[Python](https://www.python.org/), [Scala](https://www.scala-lang.org/), [Hadoop](http://hadoop.apache.org/), [Spark](http://spark.apache.org/)

---


 

__Kritik an dem `Das Magazin` Artikel und weiterführendes:__  

[Hat wirklich der große Big-Data-Zauber Trump zum Präsidenten gemacht? › Digitalistan](https://blog.wdr.de/digitalistan/hat-wirklich-der-grosse-big-data-zauber-trump-zum-praesidenten-gemacht/)

[Psychometrie, Cambridge Analytica und die Wege der Einflußnahme - YouTube](https://youtu.be/ipQScTc_9Ps)

[Parteien in Deutschland haben noch keine Position zu Wähler-Targeting (Update) netzpolitik.org](https://netzpolitik.org/2016/parteien-in-deutschland-haben-noch-keine-position-zu-waehler-targeting/)

[Donald Trump: Datenfirma Cambridge Analytica will US-Wahl entschieden haben - SPIEGEL ONLINE](http://www.spiegel.de/netzwelt/netzpolitik/donald-trump-und-die-daten-ingenieure-endlich-eine-erklaerung-mit-der-alles-sinn-ergibt-a-1124439.html)

[A Lot of People Are Saying Trump’s New Data Team Is Shady WIRED](https://www.wired.com/2016/08/trump-cambridge-analytica/)

[Big Data: Haben psychologische Facebookdaten Trumps Sieg verursacht? - Spektrum der Wissenschaft](http://www.spektrum.de/kolumne/haben-psychologische-facebookdaten-trumps-sieg-verursacht/1431745)

OCEAN:  

Openness, Conscientiousness, Extroversion, Agreeableness, Neuroticism: OCEAN-Modell


</Text>
        </Document>
        <Document ID="45">
            <Title>3.2.2.1 Speicherung</Title>
            <Text>Wenn die Aussagen der Firma Cambridge Analytica über die von ihnen gesammelten Datenmengen der Bewohner der Vereinigten Staaten von Amerika stimmen, ist es offensichtlich, dass ein einzelne relationale Datenbank nicht ausreicht, um diese 5000 Datenpunkte zu speichern. Diese Daten können aus unterschiedlichsten Typen bestehen, man spricht auch von einer Datenvielfalt in diesem Zusammenhang. Es können Bilddaten, Text, Video, Audio Informationen sein. Die von bereits geordneten Informationen in einer Tabelle bis hin zu dem „Twitter-Stream“ einer Person gehen können. Hier kommt das Hadoop Distributed File System (HDFS) zum Einsatz.  
Hadoop ist ein Open Source in Java geschriebenes Projekt, welches von Googles proprietären Google File System (GFS) und dem „MapReduce“ Framework inspiriert wurde. Mit diesem System können sehr große Datensätze zuverlässig gespeichert werden und mit hoher Bandbreite an Anwendungen, sogenannte HDFS Clients, übertragen werden. Die HDFS Architektur besteht aus einem einzigen NameNode, vielen DataNodes und dem HDFS Client. Der NameNode organisiert die Anfragen und die Ablage von Daten durch die Clients auf den DataNodes. Damit kann der NameNode als Eintrittspunkt betrachtet werden. Die DataNodes sind Kindelemente in diesem Netzwerk. Die Clients, auch EdgeNodes genannt, sind Softwareanwendungen, die von Aussen auf die Daten zugreifen oder Prozesse anstoßen. Das HDFS wurde absichtlich so entworfen, dass es auf günstiger Hardware laufen kann. Dies hat den Vorteil einer kostengünstigen Skalierung. Ebenfalls ist beim Design des Systems von vornherein mit in Rechnung genommen, dass bei einem System in dem viele Hundert oder Tausende Computer eingebunden sind, Ausfälle zu Regel gehören und nicht die Ausnahme sind. Aus diesem Grund werden Daten, die in Blöcken organisiert sind standardmäßig repliziert. Ein weiterer Grundgedanke des Systems ist, dass das Bewegen von Daten, gerade bei großen von Gigabyte oder Terabyte wie sie in Big Data auftreten können, ist kostenintensiv. Das Bewegen von Berechnungen nicht. Daher bietet das HDFS die Möglichkeit die Clients näher an die Daten heran zu bringen. Das Hadoop MapReduce Framework wurde entworfen um Speicherung- und Berechnungsaufgaben über viele tausend Server zu verteilen und bei Bedarf zu skalieren (Eine genau Erklärung von MapReduce folgt im nächsten Kapitel). Als Randnotiz sei zu bemerken, dass Hadoop mittlerweile in einer erweiterten Version 2 existiert. Diese läuft unter dem Namen YARN und trennt das „MapReduce“ Verfahren von dem Dateisystem. Hadoop liefert bereits das MapReduce Verfahren mit. Im Fall von CA wird jedoch ein weiteres Framework benutzt, da MapReduce nicht für die iterativen Prozesse des maschinellen Lernens geeignet ist.
Auch die Analyse kann nicht auf einer einzigen Maschine stattfinden. Damit setzten wir uns im folgende Kapitel „Analyse“ auseinander.  
</Text>
            <Comments>Shvachko, Konstantin, et al. "The hadoop distributed file system." 2010 IEEE 26th symposium on mass storage systems and technologies (MSST). IEEE, 2010.
N.a. "HDFS Architecture Guide." Hadoop.apache.org. 4 Aug. 2013. Web. 25 Jan. 2017. &lt;https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html&gt;
Margaret Rouse. "Apache Hadoop YARN (Yet Another Resource Negotiator)." SearchDataManagement. n.d. Web. 25 Jan. 2017. &lt;http://searchdatamanagement.techtarget.com/definition/Apache-Hadoop-YARN-Yet-Another-Resource-Negotiator&gt;</Comments>
        </Document>
        <Document ID="38">
            <Title>Big Data Mongo</Title>
            <Text>Notes Big Data Mongo DB

https://www.mongodb.com/big-data-explained
</Text>
        </Document>
        <Document ID="30">
            <Title>2 Was ist Data Science?</Title>
            <Synopsis>Abhandlung was Data Science ist</Synopsis>
            <Text>Der Begriff „Data Science“ ist seit einigen Jahren ein Buzz Word, welches immer wieder im Zusammenhang mit anderen wie „Big Data“ und „Artificial Intelligence“ auftauchen. Aber was ist dieses „Data Science“ überhaupt? Wer sind diese Daten Wissenschaftler und was machen sie?  
Geboren wurde diese neue Art von Stellenbeschreibung wohl zusammen mit dem Aufkommen von großen Datenmengen die von Unternehmen gesammelt werden. Um diesen Daten Herr zu werden bedarf es einiger Qualifikation. Der Umgang mit verschiedensten Datenbanken, die Methoden aus der Statistik, die Fähigkeit zu programmieren, das Wissen wie die Ergebnisse in eine visuelle Form gebracht werden können aus denen auch Informationen abgelesen und verstanden werden können und auch die Befähigung die Algorithmen zu schreiben, die effizient genug sind, Ergebnisse nicht erst in 2 Wochen zu liefern.  

&gt;&gt; Every time you open Facebook, one of the world’s most influential, controversial, and misunderstood algorithms springs into action. It scans and collects everything posted in the past week by each of your friends, everyone you follow, each group you belong to, and every Facebook page you’ve liked. For the average Facebook user, that’s more than 1,500 posts. If you have several hundred friends, it could be as many as 10,000. Then, according to a closely guarded and constantly shifting formula, Facebook’s news feed algorithm ranks them all, in what it believes to be the precise order of how likely you are to find each post worthwhile. Most users will only ever see the top few hundred. 
&gt; And someone needs to write an algorithm to power those features. Facebook could take all that historical data and hand it off to a very talented statistician. And she would put her immense knowledge and experience to use, diving into R and producing an excellent model that infers the relationship between all of these variables. And that would, no doubt, yield valuable insights into which ads would perform best in different situations. 

Für viele Unternehmen wird es immer wichtiger aus den bei ihnen anfallenden Daten auch Schlüsse zu ziehen. Hier kommt der Daten Wissenschaftler ins Spiel. Sei es, wie oben beschrieben, zu errechnen was jemand sehen will, um vorauszusagen, welche Produkte auch interessant sein könnten, wann der Fahrstuhl gewartet werden muss oder um vorherzusehen, wer der nächste Präsident der Vereinigten Staaten von Amerika wird. Für all diese Tätigkeiten kommen heut zu Tage Daten Wissenschafter zum Einsatz. Daher wurde von glassdoor.com auch die Stellenbeschreibung des „Data Scientist“ als der Top Job in 2016 gekürt und von Harvard Business Review (hbr.org) sogar zum „Sexiest Job of the 21st Century“. Ob diese Voraussage sich hält werden wir in einigen Jahren sehen. Sicher ist jedoch, dass in Zeiten in denen eine Boeing 737 pro Turbine innerhalb von 30 Minuten 10 terabyte Daten produziert, wir in Petabytes oder Exabytes denken, sich ein neues Feld von Beschäftigungen eröffnet. Diese Personen sind mehr als nur digitale Bibliothekare/innen. Sie müssen in der Lage sein große Datenmengen aus inkonsistenten Daten, von Video, über Text, bis Tweet und Animated GIF, zu bändigen um aus ihnen einen Schluss ziehen zu können. </Text>
            <Comments>Oremus, Will. "Who Really Controls What You See in Your Facebook Feed—and Why They Keep Changing It   ." Slate Magazine. Slate.com, 03 Jan. 2016. Web. 08 Jan. 2017. &lt;http://www.slate.com/articles/technology/cover_story/2016/01/how_facebook_s_news_feed_algorithm_works.html&gt;.
The Signal. "What is data science vs. statistics? - The Signal." The Signal. 30 Mar. 2016. Web. 8 Jan. 2017. &lt;https://blog.mixpanel.com/2016/03/30/this-is-the-difference-between-statistics-and-data-science/&gt;
Glassdoor. " Best Jobs in America ." Glassdoor. n.d. Web. 8 Jan. 2017. &lt;https://www.glassdoor.com/List/Best-Jobs-in-America-LST_KQ0,20.htm&gt;
Harvard Business Review. "Data Scientist: The Sexiest Job of the 21st Century." Harvard Business Review. 1 Oct. 2012. Web. 8 Jan. 2017. &lt;https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century&gt;
Stacey Higginbotham. "Sensor Networks Top Social Networks for Big Data." Gigaom.com. 13 Sept. 2010. Web. 15 Jan. 2017. &lt;https://gigaom.com/2010/09/13/sensor-networks-top-social-networks-for-big-data-2/&gt;
A Petabyte is approximately 1,000 Terabytes or one million Gigabytes. It's hard to visualize what a Petabyte could hold. 1 Petabyte could hold approximately 20 million 4-door filing cabinets full of text. It could hold 500 billion pages of standard printed text. It would take about 500 million floppy disks to store the same amount of data. N.a. "Megabytes, Gigabytes, Terabytes - What Are They?." Whatsabyte.com. n.d. Web. 15 Jan. 2017. &lt;http://www.whatsabyte.com/&gt;</Comments>
        </Document>
        <Document ID="16">
            <Title>About</Title>
            <Text>MLA PAPER TEMPLATE

About
This template is designed to produce an essay that adheres to the MLA (Modern Language Association of America) format. However, you should check the exact guidelines of the institution to which you are submitting your paper, as there can be slight variations in expectations (such as whether the first page has a header or not, or whether citations should use italics or underlines). See “Adjusting This Template” (below) for information on how to tweak your project to meet your requirements.

How To Use This Template
	•	Edit the “Title” document so that it contains the title of your essay, your instructor’s name and so on.
	•	Compose your essay in text documents inside the “Main Content” folder. Whether you use a single document or multiple text files to write your essay is entirely up to you - just make sure they are all inside the “Main Content” folder.
	•	Indent block quotes or other special passages using the ruler settings you require in the finished document and enclose them in a “Preserve Formatting” block. To do this, select the text of the block quote and go to Format &gt; Formatting &gt; Preserve Formatting. (The quickest way of formatting a block quote is to click in the paragraph and select “Essay Block Quote (Preserved)” from the formatting presets, either using the “Presets…” control in the format bar, or by going to the Format  menu and choosing Formatting &gt; Apply Preset - this will indent the text and apply the “Preserve Formatting” block for you.) All other text will have the default MLA indentation assigned during the compile process.
	•	This template includes an “Endnotes” document which will be used to hold any footnotes you have created in the main body of the text. If you have not created any footnotes, you should either delete this document or deselect its “Include in Compile” setting in the inspector or Compile sheet.
	•	Edit the “Works Cited” file so that it contains your own bibliography, being careful to adhere to MLA formatting.
	•	Use File &gt; Compile… to compile your essay for printing.

Adjusting This Template
	•	If you require the header to be omitted from the first page and only start on the second, go to the “Page Settings” pane in the Compile sheet, click on the “Options” tab (next to “Header and Footer”) and check “Different first page header/footer”.
	•	This template uses Times New Roman as the font. If you require a different font, such as Arial or Courier, select the text in the “Title” and “Works Cited” documents and change the font using the font panel or format bar. To change the font for the main body of the text, select the “Formatting” tab in the Compile sheet, click on the third row in the table (“Level 1+” with the icon of a single text document next to it), and then click into the text area. Finally click on the “A” button in the format bar above the text area to choose a different font. To change the header font, select your preferred font in the “Page Settings” pane of the Compile sheet.

Sample Document
The “Example Essay” PDF file in the Research folder shows how the essay will look when compiled.

Final Note
Scrivener project templates are flexible and are not intended to restrict you to a particular workflow. You can change, delete or move the files and folders contained in the template and you can create your own templates by setting up a skeletal project with the files, folders and settings you would like to use for new projects and using File &gt; Save As Template.</Text>
        </Document>
        <Document ID="46">
            <Title>3.2.2.2 Analyse</Title>
            <Text>Das Hadoop System ist die Infrastruktur zum Handhaben dieser Datenmengen. Zur Analyse dieser Daten könnte dann, wie ebenfalls aus den Anforderungen der Stellenbeschreibung hervorgeht, das Apache Spark Framework verwendet werden. Mit Spark können Daten aus einer vielen verschiedenen Quellen verarbeitet werden. Zum Beispiel auch aus dem HDFS, aber auch aus NoSQL Datenbank Systemen oder relationalen  Datenbanken. Mit Spark können Daten aus dem HDFS schneller verarbeitet werden und es existieren flexiblere Alternativen zum Hadoop „MapReduce“ Verfahren.

„MapReduce“ ist ein Verfahren welches von Google für große Datenmengen entworfen wurde. Dieses Verfahren kann in zwei Abschnitte unterteilt werden. Der Erste Abschnitt ist „Map“. Daten werden über einen Cluster von Rechner verteilt nach einer bestimmten Funktion abgearbeitet. Der Zweite Teil ist der „Reduce“ Abschnitt. Die einzelnen Teile des Clusters liefern nur einen Wert zurück. 

Um MapReduce besser zu verstehen, folgt ein kurzes Beispiel in JavaScript mit einfachen Daten. Als Erstes müssen wir einen Datensatz zur Verfügung stellen.

```js
const animals = [
    ['elefant', 'mice', 'cat', 'dog', 'unicorn', 'elefant', 'unicorn', 'cat', 'unicorn'],
    ['elefant', 'horse', 'cat', 'fish', 'mice', 'fish'],
    ['pony', 'sloth', 'frog', 'fish', 'pony']
];
```

In unserem Fall haben wir ein Multidimensionales Array mit dem Namen `animals`. Die einzelnen Datensätze in diesem Array wären im HDFS auf mehreren DataNodes verteilt. 
Es folgt die Funktion `map`. Hier wird jedem Element in einem Array ein Wert 1 zugeordnet und als neuer Datensatz bestehend aus einem doppeltem Key Value Paar in ein neues Ergebnis Array geschrieben. Diese Sammlung an Ergebnissen wird zurückgegeben. 

```js
function map (arr) {
  let result = [];
  arr.forEach(function(element, index, array) {
    result.push({animal: element, count: 1});
  });
  return result;
}
```

Als Nächstes werfen wir einen Blick auf unsere `reduce` Funktion. Hier muss jedes einzelne Objekt inspiziert werden und mit allen anderen Elementen im Array verglichen werden. Ist es noch nicht in der Ergebnismenge enthalten, wird ein neuer Eintrag erstellt. Ist es bereits enthalten, wird der entsprechende Zähler inkrementiert. In diesem speziellen Fall nutzen wir ein temporäres Objekt um wiederkehrende Einträge vergleichen zu können. Die zweite Schleife `for(let key in obj)…` ist nur dazu da um die Daten wieder in das gleiche Format aufzubereiten in dem sie auch eingetroffen sind.     

```js
function reduce (arr) {
  let result = [];
  let obj = {};
  for(let i = 0; i &lt; arr.length; i++) {
    if(obj.hasOwnProperty(arr[i].animal) !== true) {
      obj[arr[i].animal] = arr[i].count;
    }else{
      obj[arr[i].animal]++;
    }
  }
  for(let key in obj) {
    if(obj.hasOwnProperty(key)) {
      result.push({animal: key, count: obj[key]});
    }
  }
  return result;
}
```

Nun fehlt noch die ausführende Funktion `main`. Hier wird zuerst die `map` Funktion auf den rohen Datensatz angewandt und dann das Reduktionsverfahren eingeleitet. Wir erhalten nach der ersten Reduktion wiederum drei Datensätze die uns das Vorkommen von den unterschiedlichen Tieren in unseren drei Ausgangs-Datensätzen zeigen. Danach fassen wir alle drei Ergebnisse zusammen und wenden nochmals die `reduce` Funktion an um aus allen drei Sätzen einen gemeinsamen zu machen.   

```js
function main() {
  let mapped = [];
  animals.forEach(function (e) {
    mapped.push(map(e));
  });

  let reduced = [];
  mapped.forEach(function(e) {
    reduced.push(reduce(e));
  });

  let all = [];
  reduced.forEach(function(ele) {
    ele.forEach(function(e) {
      all.push(e);
    });
  });
  let result = [];
  result.push(reduce(all));
  console.log(result);
}
main();
```

Das Ergebnis ist ein Datensatz, der uns genau zeigt wie oft welches Tier in allen Datensätzen vorkommt.  

```shell
[ [ { animal: 'elefant', count: 3 },
    { animal: 'mice', count: 2 },
    { animal: 'cat', count: 3 },
    { animal: 'dog', count: 1 },
    { animal: 'unicorn', count: 3 },
    { animal: 'horse', count: 1 },
    { animal: 'fish', count: 3 },
    { animal: 'pony', count: 2 },
    { animal: 'sloth', count: 1 },
    { animal: 'frog', count: 1 } ] ]
```

Spark kommt gebündelt mit einer Bibliothek für maschinelles Lernen (MLib), was immer iterative Prozesses bedeutet, hat eine REPL (Read Eval Print Listen) Schnittstelle und kann ähnlich wir R oder Python explorativ für statistische Aufgaben verwendet werden. Seit Anfang 2014 gilt Spark als Top Level Project bei der Apache Foundation. Dieses Framework ist noch sehr jung und kann Hadoop oder YARN (Hadoop 2) noch nicht ersetzten, wird aber als zukunftsträchtiges Projekt angesehen.  
Wenn Datenmengen bearbeitet werden sollen, die auf einer einzigen Maschine existieren und verarbeitet werden können, kommt auch gerne die Programmiersprache Python, in ihren interaktiven Umgebungen wie iPython oder Jupyter, mit Paketen wie scikit-learn oder pandas zum Einsatz. Pandas zum Bearbeiten von Datenstrukturen und scikit-learn zum Analysieren von Daten. Weiter übliche Module sind Matplotlib für die Ausgabe als Plot um die Ergebnisse auch sichtbar zu machen. Dies ist eine oft unterschätzter Anteil an Arbeit. Aus Tabellen und Zahlenkolonnen lässt sich nur schlecht ein Verhalten von Werten ablesen. Als einfaches Beispiel hierzu kann das Anscombe Quartett betrachtet werden.

    +------+------+------+------+-------+------+-------+------+
    |  x1  |  x2  |  x3  |  x4  |  y1   |  y2  |  y3   |  y4  |
    +======+======+======+======+=======+======+=======+======+
    |  10  |  10  |  10  |  8   | 8.04  | 9.14 | 7.46  | 6.58 |
    +------+------+------+------+-------+------+-------+------+
    |  8   |  8   |  8   |  8   | 6.95  | 8.14 | 6.77  | 5.76 |
    +------+------+------+------+-------+------+-------+------+
    |  13  |  13  |  13  |  8   | 7.58  | 8.74 | 12.74 | 7.71 |
    +------+------+------+------+-------+------+-------+------+
    |  9   |  9   |  9   |  8   | 8.81  | 8.77 | 7.11  | 8.84 |
    +------+------+------+------+-------+------+-------+------+
    |  11  |  11  |  11  |  8   | 8.33  | 9.26 | 7.81  | 8.47 |
    +------+------+------+------+-------+------+-------+------+
    |  14  |  14  |  14  |  8   | 9.96  | 8.1  | 8.84  | 7.04 |
    +------+------+------+------+-------+------+-------+------+
    |  6   |  6   |  6   |  8   | 7.24  | 6.13 | 6.08  | 5.25 |
    +------+------+------+------+-------+------+-------+------+
    |  4   |  4   |  4   |  19  | 4.26  | 3.1  | 5.39  | 12.5 |
    +------+------+------+------+-------+------+-------+------+
    |  12  |  12  |  12  |  8   | 10.84 | 9.13 | 8.15  | 5.56 |
    +------+------+------+------+-------+------+-------+------+
    |  7   |  7   |  7   |  8   | 4.82  | 7.26 | 6.42  | 7.91 |
    +------+------+------+------+-------+------+-------+------+
    |  5   |  5   |  5   |  8   | 5.68  | 4.74 | 5.73  | 6.89 |
    +------+------+------+------+-------+------+-------+------+

![Anscombe Quartett Plot](./images/anscombe-quartet.png)  

Aus der oben stehenden Tabelle lassen sich wenig bis gar keine Schlüsse auf das Verhalten der Werte schließen. Durch die Visualisierung der Werte kann schnell ein Muster oder eine Abweichung festgestellt werden.  </Text>
            <Comments>Dean, Jeffrey, and Sanjay Ghemawat. "MapReduce: simplified data processing on large clusters." Communications of the ACM 51.1 (2008): 107-113.
Sean Owen. "Why Apache Spark is a Crossover Hit for Data Scientists - Cloudera Engineering Blog." Cloudera Engineering Blog. 3 Mar. 2014. Web. 22 Jan. 2017. &lt;http://blog.cloudera.com/blog/2014/03/why-apache-spark-is-a-crossover-hit-for-data-scientists/&gt;
N.a. "The Apache Software Foundation Announces Apache™ Spark™ as a Top-Level Project : The Apache Software Foundation Blog." Blogs.apache.org. 20 Jan. 2017. Web. 22 Jan. 2017. &lt;https://blogs.apache.org/foundation/entry/the_apache_software_foundation_announces50&gt;
N.a. "Jupyter and the future of IPython — IPython." Ipython.org. 9 Jan. 2017. Web. 22 Jan. 2017. &lt;http://ipython.org/index.html&gt;
N.a. "Project Jupyter." Jupyter.org. 17 Jan. 2017. Web. 22 Jan. 2017. &lt;http://www.jupyter.org&gt;
N.a. "scikit-learn: machine learning in Python — scikit-learn 0.18.1 documentation." Scikit-learn.org. n.d. Web. 22 Jan. 2017. &lt;http://scikit-learn.org/stable/&gt;
N.a. "Python Data Analysis Library — pandas: Python Data Analysis Library." Pandas.pydata.org. 26 Dec. 2016. Web. 22 Jan. 2017. &lt;http://pandas.pydata.org/&gt;
N.a. "Matplotlib: Python plotting — Matplotlib 2.0.0 documentation." Matplotlib.org. 19 Jan. 2017. Web. 22 Jan. 2017. &lt;http://matplotlib.org/&gt;
Turner, Stephen. "Using and Abusing Data Visualization: Anscombe’s Quartet and Cheating Bonferroni." R-bloggers. 26 Feb. 2015. Web. 25 Jan. 2017. &lt;https://www.r-bloggers.com/using-and-abusing-data-visualization-anscombes-quartet-and-cheating-bonferroni/&gt;</Comments>
        </Document>
        <Document ID="39">
            <Title>4 Ausblick</Title>
            <Text>Algorithmen, maschinelles Lernen und künstliche Intelligenz halten Einzug in jeden Bereich unseres Lebens. Automatisiertes Handel ist schon seit Jahren üblich. „Big Data“ ist ein Interessenfeld für viele Unternehmen. Daten Wissenschaften sind ein neues Feld von Studien, von dem wir noch nicht sagen können, wo es uns hin führen wird. Denn es ist schwer abzusehen was in den nächsten 5, 10, 15 Jahren auf diesen Feldern passieren wird. Eines ist jedoch klar. Die Mengen an Daten werden nicht geringer. Mit dem Bereich des „Internet of Things“ (IoT) kommen laut Gartner bis im Jahr 2020 mehr als 20 Milliarden Geräte ans Netz. Ältere Voraussagen gingen noch von 75 Milliarden Geräte. All diese Objekte werden Daten erzeugen, an einen Server spielen oder sie durch ihn hin druchleiten und dann? Genauso werden die sozialen Netzwerke versuchen immer weiter in unser Leben einzudringen. Die Idee von Facebook solargetriebene Flugzeuge, die Internet Zugang bis in die entlegensten Winkel der Welt bringen, zu bauen, ist bestimmt nicht aus reinem Altruismus geboren. Wer das Netz liefert kann auch sehen, was gesehen wird. Die Liste geht weiter und weiter. Von Amazon Echo, über Googles selbstfahrende Autos oder Heim-Automations-Systemen, zu Snapchats Brillen mit Videofunktion. Basierend auf diesen Informationen werden für alle Bereiche des Lebens Modelle unseres Verhaltens und unserer Vorlieben entwickelt um uns noch besser kontrollieren oder bewerben zu können. Sei es um uns Serien zu liefern die genau unseren Interessen entsprechen oder um die richtige Partei zu wählen, das richtige Produkt zu kaufen oder um uns vor uns selber zu schützen. Für den einen mag diese Aussicht spannend sein für den anderen erschreckend. Sicher, egal ob „Schöne neue Welt“ oder „1984“, wir leben in spannenden Zeiten. </Text>
            <Comments>N.a. "Gartner Says 6.4 Billion Connected ." Gartner.com. n.d. Web. 22 Jan. 2017. &lt;http://www.gartner.com/newsroom/id/3165317&gt;
Tony Danova. "Morgan Stanley: 75 Billion Devices Will Be Connected To The Internet Of Things By 2020." Business Insider. 2 Oct. 2013. Web. 22 Jan. 2017. &lt;http://www.businessinsider.com/75-billion-devices-will-be-connected-to-the-internet-by-2020-2013-10&gt;
Larry Dignan. "Facebook's 10-year roadmap outlined, eyes AI, VR, Internet access infrastructure | ZDNet." ZDNet. 12 Apr. 2016. Web. 22 Jan. 2017. &lt;http://www.zdnet.com/article/facebooks-10-year-roadmap-outlined-eyes-ai-vr-internet-access-infrastructure/&gt;</Comments>
        </Document>
        <Document ID="31">
            <Title>3 Data Science In der Anwendung</Title>
            <Synopsis>Zusammenfassung der Anwendungen</Synopsis>
            <Text>Wie bereits im vorherigen Kapitel erwähnt, werden unglaubliche Datenmengen von Unternehmen gesammelt, gebündelt und ausgewertet. Es wird „getracked“ und gespeichert, wo es nur geht. Ein Unternehmen wie Google, _wenn es überhaupt noch ein zweites Unternehmen wie Google gibt_, sammelt über jede Art von Dienst den es zur Verfügung stellt, um so viele Data Points wie möglich über Nutzer/innen zu erhalten. Die offensichtlichen Punkte wo über uns gesammelt wird, sind Google Suchhistorie, Tracking Cookies, Adsense, Analytics, Youtube, Google+, Gmail, Google Drive, Google Documents, Android und viele mehr.
Nicht so offensichtlich jedoch auch vorstellbar als Methode uns als Einzelperson zu identifizieren sind Dinge wie Anschlagdynamik bei der Eingabe mit der Tastatur oder die Art wie wir uns verschreiben. Was Google damit macht, ist uns allen bekannt. Besser Werbung platzieren. Doch wie sieht es für die anderen Unternehmen aus? Besonders von denen, die nicht ihr Geld mit dem Platzieren von Werbung verdienen, ist unser Bild noch nebulös. Welchen Sinn stiftet es diese Unmengen an Daten zu sammeln, zu speichern, vorzuhalten und wie kann daraus Gewinn geschlagen werden?

Oder um es einfacher zu sagen: „Wie findet Data Science Anwendung?“  

In den folgenden beiden Unterabschnitten werden wir die Unternehmen Netflix und Cambridge Analytica betrachten, um zwei weitere Modelle aufzuzeigen in den „Big Data“ eine zentrale Rolle spielt.  </Text>
            <Comments>Long, Moe. "How Much Does Google Really Know About You?." MakeUseOf. n.d. Web. 15 Jan. 2017. &lt;http://www.makeuseof.com/tag/how-much-google-know-about-you/&gt;</Comments>
        </Document>
        <Document ID="24">
            <Title>Works Cited</Title>
        </Document>
        <Document ID="8">
            <Title>6 Quellen</Title>
            <Synopsis>Quellen für Texte und Bilder</Synopsis>
            <Text>Any footnotes you created in your paper will get inserted here upon Compile (this purple bubble will be removed automatically). If you don’t have any footnotes, you can deselect “Include in Compile” for this document in the Inspector or Compile settings, or just delete it completely.</Text>
        </Document>
        <Document ID="9">
            <Title>Body</Title>
        </Document>
    </Documents>
</SearchIndexes>