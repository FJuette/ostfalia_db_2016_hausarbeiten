{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf760
{\fonttbl\f0\fnil\fcharset0 Vollkorn-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c100000;}
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\fi366\pardirnatural

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
Zum Grauen vieler zog zu Beginn des Dezembers 2016 ein Artikel mit dem Titel {\field{\*\fldinst{HYPERLINK "scrivcmt://D4D2048C-222E-4C4E-82B2-4BDF1D658706"}}{\fldrslt \'84Ich habe nur gezeigt, dass es die Bombe gibt\'93}} seine Runde durch die verschiedensten Sozialen Medien. In ihm wird erl\'e4utert wie psychologische Methoden und \'f6ffentlich und zug\'e4nglich oder erwerbbare Daten von der Firma [\'84Cambridge Analytica\'93 (CA)]({\field{\*\fldinst{HYPERLINK "https://cambridgeanalytica.org/"}}{\fldrslt \cf2 \cb3 https://cambridgeanalytica.org/}}) genutzt wurden um Donald Trump zum Sieg \'fcber Hillary Clinton in den Pr\'e4sidentschaftswahlen der U.S.A. von 2016  zu verhelfen. Ob dies wirklich eins zu eins so statt fand soll an dieser Stelle bezweifelt werden. (Siehe {\field{\*\fldinst{HYPERLINK "scrivcmt://0A55559A-5546-4B1F-935B-2E01F359760B"}}{\fldrslt WDR Blog}}, {\field{\*\fldinst{HYPERLINK "scrivcmt://1828AA30-3B5E-449C-B039-C0554443CCDC"}}{\fldrslt Spiegel Online}}, {\field{\*\fldinst{HYPERLINK "scrivcmt://A3877B37-F091-4FE1-AFD0-3B74EE982AF5"}}{\fldrslt wired.com}}, {\field{\*\fldinst{HYPERLINK "scrivcmt://0225408F-0A6F-4FAA-8933-4B0B5F671BDE"}}{\fldrslt bloomberg.com}} oder {\field{\*\fldinst{HYPERLINK "scrivcmt://0A92E7A0-88B3-4B14-8903-C3198878DDDC"}}{\fldrslt spektrum.de}})Es gibt einige Tatsachen die dagegen sprechen. So ist ein Artikel dessen gesamte Beweisf\'fchrung sich auf die Aussagen von zwei Personen st\'fctzt, von denen eine noch ein gro\'dfes Interesse daran hat genau so wahrgenommen zu werden, wenig fundiert. Ebenfalls trifft der Artikel einen bestimmten Nerv, schl\'e4gt genau in die Richtige Kerbe zum Richtigen Zeitpunkt. Nach einem langen und schmutzigen Wahlkampf, gewinnt der von dem es die wenigsten geglaubt h\'e4tten. Da ist es nur recht und billig einen S\'fcndenbock zu finden. Nicht soziale Spannung die wir uns nicht vorstellen k\'f6nnen war es, es muss eine neue bisher unbekannte Technologie 
\i (vielleicht eine k\'fcnstliche Intelligenz?)
\i0  gewesen sein und irgendwie spielen unsere Daten die Facebook \'fcber uns sammelt da mit .  \
Dennoch erweckt dies so sehr die Aufmerksamkeit der Autoren, dass hier einmal die Methoden und der Technologie Stack dieser Firma so weit es geht unter die Lupe genommen werden soll.   \
\
### Die Dienstleistung  \
\
Nach eigenen Aussagen kann die Firma CA hinzugezogen werden um auf eine neue Weise Kontakt zu seinem Publikum aufzunehmen. Auf ihrer Website versprechen sie bis zu 5000 Daten Punkten pro Person (derzeit nur US B\'fcrger) zu sammeln und deren Verhalten auf Grund von verschiedenen Modellen vorauszusagen. \
{\field{\*\fldinst{HYPERLINK "scrivcmt://71ECE6D6-F9CE-4767-8DEB-FD2D79E581A2"}}{\fldrslt > ## 5,000 data points per person  \
> We collect up to 5,000 data points on over 220 million Americans, and use more than 100 data variables to model target audience groups and predict the behavior of like-minded people.}}\
\
Laut Angaben von Alexander Nix (CEO CA) auf dem{\field{\*\fldinst{HYPERLINK "scrivcmt://29122120-2ECA-40CA-89C0-232DDBF9F84E"}}{\fldrslt  2016 Concordia Summit}}, werden Demographische Daten Verbraucher-Daten und Daten aus dem Bereich Lifestyle mit psychographischen Daten von Unternehmen wie [acxiom](http://www.acxiom.com/), [infogroup](http://www.infogroup.com/), [Experian](http://www.experian.com/), [data trust](http://thedatatrust.com/), [Facebook](https://www.facebook.com/), [L2](http://www.l2political.com/), [Aristotle](http://aristotle.com/), GOP, MRI , [Nielsen](http://www.nielsen.com/), [Magellan strategies](http://magellanstrategies.com/) verbunden.  \
\
### Der Technologie Stack  \
\
Nat\'fcrlich l\'e4sst eine Firma wie CA sich nicht direkt in die Karten schauen. Aus den Stellenangeboten f\'fcr Data Engineers und besonders f\'fcr Data Scientists auf ihrer Seite lassen sich jedoch einige Schl\'fcsse ziehen. Bei Datenbanken werden Erfahrungen und F\'e4higkeiten im Umgang mit  MySQL und, aus dem Sektor der NoSQL Datenbanken, MongoDB erw\'fcnscht. Im Bereich Big Data scheinen die Frameworks Spark und Hadoop zum Einsatz zu kommen und die gew\'fcnschten Sprachen sind Python, Java oder Scala und entsprechenden Objekt Orientierten Programmier Paradigmen. Des weiteren nat\'fcrlich der Umgang mit Versions Kontroll Systemen.   \
\
#### Speicherung\
\
Wenn die Behauptung der Firma CA stimmt ist es offensichtlich, dass ein relationale Datenbank nicht ausreicht um diese 4000 Datenpunkte zu speichern. Auch die Analyse kann nicht auf einer einzelnen Maschine stattfinden. {\field{\*\fldinst{HYPERLINK "scrivcmt://E2D00F98-DEF6-4242-BF6C-C311F56942EA"}}{\fldrslt \cf2 \cb3 Hier kommt das Hadoop Distributed File System (HDFS) zum Einsatz. Hadoop ist ein Open Source (Java) Projekt, welches von Googles propriet\'e4ren Google File System (GFS) und dem MapReduce Framework inspiriert wurde.  Mit diesem System k\'f6nnen sehr gro\'dfe Datens\'e4tze zuverl\'e4ssig gespeichert werden und mit hoher Bandbreite an Anwendungen, sogenannte HDFS Clients, \'fcbertragen werden. Die HDFS Architektur besteht aus einem einzelnen NameNode, vielen DataNodes und dem HDFS Client. Der NameNode organisiert die Anfragen und die Ablage von Daten von den DataNodes durch die Clients. Das Hadoop MapReduce Framework wurde entworfen um Speicherung- und Berechnungsaufgaben \'fcber viele tausend Server zu verteilen und bei Bedarf zu skalieren.}} \
\
#### Analyse  \
\
Das Hadoop System ist die Infrastruktur zum handhaben dieser Datenmengen. Zur Analyse dieser Daten k\'f6nnte dann, wie ebenfalls aus den Anforderungen der Stellenbeschreibung hervorgeht, das Apache Spark Framework verwendet werden. Mit Spark k\'f6nnen Daten aus einer vielen verschiedenen Quellen verarbeitet werden. Zum Beispiel auch aus dem HDFS, aber auch aus NoSQL Datenbank Systemen oder relationalen  Datenbanken. Mit Spark k\'f6nnen Daten aus dem HDFS schneller verarbeitet werden und es existieren flexiblere Alternativen zum Hadoop MapReduce Verfahren.\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\fi366\pardirnatural
{\field{\*\fldinst{HYPERLINK "scrivcmt://97350906-0A1E-477B-B014-013EEC664E59"}}{\fldrslt \cf2 \cb3 MapReduce ist ein Verfahren welches von Google f\'fcr gro\'dfe Datenmengen entworfen wurde. Map: Daten werden \'fcber einen Cluster von Rechner verteilt nach einer bestimmten Funktion abgearbeitet. Reduce: Die einzelnen Teile des Clusters liefern nur einen Wert zur\'fcck.}} wird{\field{\*\fldinst{HYPERLINK "scrivcmt://FD141573-C914-4E70-8324-D47DF05B2DDB"}}{\fldrslt \cf2 \cb3 Spark kommt geb\'fcndelt mit einer Bibliothek f\'fcr maschinelles Lernen (MLib), was immer iterative Prozesses bedeutet, hat eine REPL (Read Eval Print Listen) Schnittstelle und kann \'e4hnlich wir R oder Python explorativ f\'fcr statistische Aufgaben verwendet werden.}} Seid Anfang 2014 gilt Spark als {\field{\*\fldinst{HYPERLINK "scrivcmt://76C4AF3A-74F2-41B0-B4C2-B979637800FA"}}{\fldrslt \cf2 \cb3 Top Level Project bei der Apache Foundation}}}