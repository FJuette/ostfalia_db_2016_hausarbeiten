# 5. Use Cases
As discussed above Spark has a lot of advantages and innovative technologies, it is cost-efficient and could be used in different programming languages. But how to know whether Spark is suitable for the purpoces you are aiming or not? Here are some typical use cases for Apache Spark:

## 5.1 Streaming analytics
Spark is not the first Big Data tool for handling streaming, but it is the first one to integrate it with the rest of the analytics environment. You can use the same code for streaming analytic operations as you can for batch, and use Spark to compute over both the stream and historical data. This increases productivity, consistency, and maintainability of analytic procedures.

## 5.2 Model building and machine learning
Spark is ideal for building models for analytical purposes. Before the invettion of Spark, Big Data modelers typically built their models in a language such as R or SAS, then threw them to data engineers to re-implement in Java for production on Hadoop. This workflow limits efficiency, extends iteration time, and is a source of potential errors. With Spark, the same platform is used for model building and deployment, making the process much more efficient, and allowing data analysts hands-on insight into model performance.

## 5.3 Research analytics
One of the Spark's main benefits is that you no longer need to maintain different environments for research and production work. The relatively long execution times of a Hadoop MapReduce job make it difficult for hands-on exploration of data, because data scientists typically still must sample data if they want to move quickly. Thanks to the speed of Spark’s in-memory capabilities, interactive exploration can now happen completely within Spark, without need for Java engineering or sampling of the data. Whether the development language of choice is SQL, R, Python, or Scala, Spark interfaces to each. Platforms such as Databricks Cloud and Apache Zeppelin aim to bring this power to a browser based interface. Spark will even run on a data scientist’s laptop, meaning they can approach those small use cases with exactly the same tooling.

## 5.4 Analysis of Graphs
As already described above Spark has a built-in GraphX component, which brings all the benefits of using Spark's environment to graph computation. This enables use cases such as social network analysis, fraud detection, and recommendations. While there are other graph databases to choose from, they typically involve multiple systems to build out the entire computation pipeline. Spark’s integration of the platform brings flexibility and resilience to graph computing, as well as the ability to work with graph and non-graph sources.