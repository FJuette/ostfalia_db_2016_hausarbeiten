{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf760
{\fonttbl\f0\fnil\fcharset0 Vollkorn-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c100000;}
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\fi366\pardirnatural

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
Wenn die Aussagen der Firma Cambridge Analytica \'fcber die von ihnen gesammelten Datenmengen der Bewohner der Vereinigten Staaten von Amerika stimmen, ist es offensichtlich, dass ein einzelne relationale Datenbank nicht ausreicht, um diese 5000 Datenpunkte zu speichern. Diese Daten k\'f6nnen aus unterschiedlichsten Typen bestehen, man spricht auch von einer Datenvielfalt in diesem Zusammenhang. Es k\'f6nnen Bilddaten, Text, Video, Audio Informationen sein. Die von bereits geordneten Informationen in einer Tabelle bis hin zu dem \'84Twitter-Stream\'93 einer Person gehen k\'f6nnen. Hier kommt das Hadoop Distributed File System (HDFS) zum Einsatz.  \
{\field{\*\fldinst{HYPERLINK "scrivcmt://CE7239FC-F109-4391-AB9C-3E41FC78D9F2"}}{\fldrslt Hadoop ist ein Open Source in Java geschriebenes Projekt, welches von Googles propriet\'e4ren Google File System (GFS) und dem \'84MapReduce\'93 Framework inspiriert wurde. Mit diesem System k\'f6nnen sehr gro\'dfe Datens\'e4tze zuverl\'e4ssig gespeichert werden und mit hoher Bandbreite an Anwendungen, sogenannte HDFS Clients, \'fcbertragen werden. Die HDFS Architektur besteht aus einem einzigen NameNode, vielen DataNodes und dem HDFS Client. Der NameNode organisiert die Anfragen und die Ablage von Daten durch die Clients auf den DataNodes. Damit kann der NameNode als Eintrittspunkt betrachtet werden. Die DataNodes sind Kindelemente in diesem Netzwerk. Die Clients, auch EdgeNodes genannt, sind Softwareanwendungen, die von Aussen auf die Daten zugreifen oder Prozesse ansto\'dfen.}} {\field{\*\fldinst{HYPERLINK "scrivcmt://0075650A-0F29-4085-8733-46C99F0A9302"}}{\fldrslt Das HDFS wurde absichtlich so entworfen, dass es auf g\'fcnstiger Hardware laufen kann. Dies hat den Vorteil einer kosteng\'fcnstigen Skalierung. Ebenfalls ist beim Design des Systems von vornherein mit in Rechnung genommen, dass bei einem System in dem viele Hundert oder Tausende Computer eingebunden sind, Ausf\'e4lle zu Regel geh\'f6ren und nicht die Ausnahme sind. Aus diesem Grund werden Daten, die in Bl\'f6cken organisiert sind standardm\'e4\'dfig repliziert. Ein weiterer Grundgedanke des Systems ist, dass das Bewegen von Daten, gerade bei gro\'dfen von Gigabyte oder Terabyte wie sie in Big Data auftreten k\'f6nnen, ist kostenintensiv. Das Bewegen von Berechnungen nicht. Daher bietet das HDFS die M\'f6glichkeit die Clients n\'e4her an die Daten heran zu bringen.}} Das Hadoop MapReduce Framework wurde entworfen um Speicherung- und Berechnungsaufgaben \'fcber viele tausend Server zu verteilen und bei Bedarf zu skalieren (Eine genau Erkl\'e4rung von MapReduce folgt im n\'e4chsten Kapitel). {\field{\*\fldinst{HYPERLINK "scrivcmt://D71DCABB-DAE7-4C4D-93C2-8B6939B43891"}}{\fldrslt Als Randnotiz sei zu bemerken, dass Hadoop mittlerweile in einer erweiterten Version 2 existiert. Diese l\'e4uft unter dem Namen YARN und trennt das \'84MapReduce\'93 Verfahren von dem Dateisystem.}} Hadoop liefert bereits das MapReduce Verfahren mit. Im Fall von CA wird jedoch ein weiteres Framework benutzt, da MapReduce nicht f\'fcr die iterativen Prozesse des maschinellen Lernens geeignet ist.\
Auch die Analyse kann nicht auf einer einzigen Maschine stattfinden. Damit setzten wir uns im folgende Kapitel \'84Analyse\'93 auseinander.  \
}